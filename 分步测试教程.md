# PAROL6 机械臂系统 - 分步测试教程

> 本教程将带你从零开始，一步一步测试系统的所有功能。每个步骤都有详细说明、预期结果和问题排查。

---

## 📋 测试清单

- [ ] 阶段 1：环境准备和安装
- [ ] 阶段 2：基础连接测试
- [ ] 阶段 3：基础运动测试
- [ ] 阶段 4：夹爪控制测试
- [ ] 阶段 5：高级运动测试
- [ ] 阶段 6：视觉系统测试
- [ ] 阶段 7：Gemini AI 控制测试

---

## 🔧 阶段 1：环境准备和安装

### 步骤 1.1：检查硬件连接

**操作**：
1. 确认机器人电源已连接但**暂未开启**
2. 确认机器人通过 USB 线连接到电脑
3. 确认急停按钮处于可触及位置
4. 清理机器人工作区域内的障碍物

**验证**：
```bash
# Windows - 检查 COM 端口
# 打开设备管理器 → 端口(COM和LPT) → 查找 USB Serial Port

# Linux - 检查串口设备
ls /dev/ttyUSB* /dev/ttyACM*
# 应该看到类似 /dev/ttyUSB0 或 /dev/ttyACM0
```

**预期结果**：
- Windows: 看到 COM3、COM4 等端口
- Linux: 看到 /dev/ttyUSB0 或类似设备

**如果失败**：
- 检查 USB 线是否插好
- 尝试更换 USB 端口
- Windows: 安装 USB 驱动程序
- Linux: 添加用户到 dialout 组：`sudo usermod -a -G dialout $USER`（需要重新登录）

---

### 步骤 1.2：安装 Python 依赖

**操作**：

创建测试脚本 `check_dependencies.py`：

```python
#!/usr/bin/env python3
"""依赖检查脚本"""

import sys

def check_module(name, package_name=None):
    """检查模块是否安装"""
    if package_name is None:
        package_name = name
    try:
        __import__(name)
        print(f"✓ {package_name:30s} - 已安装")
        return True
    except ImportError:
        print(f"✗ {package_name:30s} - 未安装")
        return False

print("=" * 60)
print("检查核心依赖（服务器端必需）")
print("=" * 60)

core_modules = [
    ('roboticstoolbox', 'roboticstoolbox-python'),
    ('numpy', 'numpy'),
    ('scipy', 'scipy'),
    ('spatialmath', 'spatialmath'),
    ('serial', 'pyserial'),
    ('oclock', 'oclock'),
    ('keyboard', 'keyboard'),
]

core_ok = all(check_module(name, pkg) for name, pkg in core_modules)

print("\n" + "=" * 60)
print("检查视觉依赖（视觉功能必需）")
print("=" * 60)

vision_modules = [
    ('cv2', 'opencv-python'),
    ('pyrealsense2', 'pyrealsense2'),
    ('PIL', 'Pillow'),
]

vision_ok = all(check_module(name, pkg) for name, pkg in vision_modules)

print("\n" + "=" * 60)
print("检查 AI 依赖（Gemini 控制必需）")
print("=" * 60)

ai_modules = [
    ('google.genai', 'google-genai'),
    ('dotenv', 'python-dotenv'),
    ('pyaudio', 'pyaudio'),
]

ai_ok = all(check_module(name, pkg) for name, pkg in ai_modules)

print("\n" + "=" * 60)
print("总结")
print("=" * 60)

if core_ok:
    print("✓ 核心依赖：完整")
else:
    print("✗ 核心依赖：缺失")
    print("  安装命令：pip3 install roboticstoolbox-python==1.0.3 numpy==1.23.4 scipy==1.11.4 spatialmath pyserial oclock keyboard")

if vision_ok:
    print("✓ 视觉依赖：完整")
else:
    print("✗ 视觉依赖：缺失")
    print("  安装命令：pip3 install opencv-python pyrealsense2 Pillow")

if ai_ok:
    print("✓ AI 依赖：完整")
else:
    print("✗ AI 依赖：缺失（不影响基础功能）")
    print("  安装命令：pip3 install google-genai python-dotenv pyaudio")

if core_ok:
    print("\n✓ 可以开始基础功能测试")
if core_ok and vision_ok:
    print("✓ 可以开始视觉功能测试")
if core_ok and vision_ok and ai_ok:
    print("✓ 可以开始 AI 控制测试")
```

运行检查：
```bash
cd /path/to/PAROL6-Python-API-Gemini-Vision-Public
python check_dependencies.py
```

**预期结果**：
```
✓ roboticstoolbox-python      - 已安装
✓ numpy                        - 已安装
✓ scipy                        - 已安装
...
✓ 核心依赖：完整
✓ 可以开始基础功能测试
```

**如果缺少依赖**：
按照输出的安装命令逐个安装缺失的包。

---

### 步骤 1.3：配置串口

**操作**：

在 `Headless/` 目录下创建 `com_port.txt` 文件：

```bash
cd Headless

# Windows 示例（根据设备管理器中的实际端口号）
echo "COM3" > com_port.txt

# Linux 示例
echo "/dev/ttyUSB0" > com_port.txt
```

或者手动创建文件：
- Windows: 在 `Headless/` 目录创建 `com_port.txt`，内容为 `COM3`（替换为实际端口）
- Linux: 内容为 `/dev/ttyUSB0`（替换为实际设备）

**验证**：
```bash
cat com_port.txt
# 应该显示你的串口名称
```

---

### 步骤 1.4：配置 Gemini API（可选）

如果要测试 AI 控制功能，需要配置 API 密钥。

**操作**：

1. 获取 API 密钥：https://makersuite.google.com/app/apikey
2. 在项目根目录创建 `.env` 文件：

```bash
cd /path/to/PAROL6-Python-API-Gemini-Vision-Public
nano .env
# 或使用其他文本编辑器
```

添加内容：
```
GEMINI_API_KEY=你的实际API密钥
```

**验证**：
```bash
cat .env
# 应该显示 GEMINI_API_KEY=AIza...
```

---

## 🔌 阶段 2：基础连接测试

### 步骤 2.1：启动机器人控制服务器

**操作**：

1. **开启机器人电源**
2. 等待机器人初始化完成（约 5 秒）
3. 打开终端，启动服务器：

```bash
cd Headless
python headless_commander.py
```

**预期输出**：
```
PAROL6 Headless Commander Starting...
Connecting to robot on port COM3...
✓ Serial connection established
✓ Robot controller initialized
✓ Kinematics system loaded
✓ Command queue ready
✓ Emergency stop monitoring active

Auto-homing robot...
Homing sequence started...
Homing in progress...
✓ Homing complete

✓ Robot ready
Listening for UDP commands on port 5001
Press 'e' to enable/disable robot after E-stop
Press 'q' to quit

Main loop running at 100Hz...
```

**预期行为**：
- 机器人自动执行回零（homing）动作
- 所有关节移动到零位
- 服务器开始监听 UDP 端口 5001

**如果失败**：

| 错误信息 | 原因 | 解决方案 |
|---------|------|---------|
| `Serial port not found` | 串口配置错误 | 检查 `com_port.txt` 中的端口名称 |
| `Permission denied` | 串口权限不足 | Linux: `sudo chmod 666 /dev/ttyUSB0` 或添加到 dialout 组 |
| `Module not found` | 缺少依赖 | 运行 `check_dependencies.py` 检查 |
| 机器人不动 | 急停按钮被按下 | 释放急停按钮，按 'e' 键重新启用 |

**重要提示**：
- 保持这个终端窗口打开，不要关闭
- 机器人回零时注意观察，确保运动正常
- 如果运动异常，立即按下急停按钮

---

### 步骤 2.2：测试基础 API 连接

**操作**：

打开**新的终端窗口**（保持服务器运行），创建测试脚本 `test_01_connection.py`：

```python
#!/usr/bin/env python3
"""测试 1：基础连接测试"""

import sys
sys.path.insert(0, './Headless')

from robot_api import *
import time

print("=" * 60)
print("测试 1：基础连接测试")
print("=" * 60)

# 测试 1.1：查询机器人状态
print("\n[测试 1.1] 查询机器人是否停止...")
try:
    is_stopped = is_robot_stopped()
    if is_stopped is not None:
        print(f"✓ 连接成功！机器人状态：{'已停止' if is_stopped else '运动中'}")
    else:
        print("✗ 无法获取机器人状态")
        sys.exit(1)
except Exception as e:
    print(f"✗ 连接失败：{e}")
    print("\n请检查：")
    print("  1. headless_commander.py 是否正在运行？")
    print("  2. 防火墙是否阻止了 UDP 5001 端口？")
    sys.exit(1)

time.sleep(0.5)

# 测试 1.2：查询关节角度
print("\n[测试 1.2] 查询当前关节角度...")
angles = get_robot_joint_angles()
if angles:
    print(f"✓ 当前关节角度：")
    for i, angle in enumerate(angles, 1):
        print(f"   关节 {i}: {angle:7.2f}°")
else:
    print("✗ 无法获取关节角度")

time.sleep(0.5)

# 测试 1.3：查询末端位置
print("\n[测试 1.3] 查询末端执行器位置...")
pose = get_robot_pose()
if pose:
    print(f"✓ 当前位置姿态：")
    print(f"   位置 (mm):  X={pose[0]:7.2f}, Y={pose[1]:7.2f}, Z={pose[2]:7.2f}")
    print(f"   姿态 (deg): Rx={pose[3]:7.2f}, Ry={pose[4]:7.2f}, Rz={pose[5]:7.2f}")
else:
    print("✗ 无法获取位置姿态")

time.sleep(0.5)

# 测试 1.4：查询 IO 状态
print("\n[测试 1.4] 查询 I/O 状态...")
io_status = get_robot_io()
if io_status:
    print(f"✓ I/O 状态：")
    print(f"   输入 1: {io_status[0]}  输入 2: {io_status[1]}")
    print(f"   输出 1: {io_status[2]}  输出 2: {io_status[3]}")
    print(f"   急停状态: {'按下' if io_status[4] else '释放'}")

    if io_status[4]:
        print("\n⚠ 警告：急停按钮被按下！")
        print("   请释放急停按钮，然后在服务器终端按 'e' 键重新启用机器人")
else:
    print("✗ 无法获取 I/O 状态")

time.sleep(0.5)

# 测试 1.5：查询完整状态
print("\n[测试 1.5] 查询完整机器人状态...")
status = get_robot_status()
if status:
    print("✓ 完整状态获取成功")
    print(f"   运动状态：{'已停止' if status['stopped'] else '运动中'}")
    print(f"   急停状态：{'按下' if status['estop'] else '释放'}")
else:
    print("✗ 无法获取完整状态")

print("\n" + "=" * 60)
print("连接测试完成！")
print("=" * 60)
print("\n如果所有测试都显示 ✓，说明连接正常，可以进行运动测试。")
print("如果有 ✗，请根据错误信息排查问题。")
```

运行测试：
```bash
python test_01_connection.py
```

**预期输出**：
```
============================================================
测试 1：基础连接测试
============================================================

[测试 1.1] 查询机器人是否停止...
✓ 连接成功！机器人状态：已停止

[测试 1.2] 查询当前关节角度...
✓ 当前关节角度：
   关节 1:    0.00°
   关节 2:  -90.00°
   关节 3:  180.00°
   关节 4:    0.00°
   关节 5:    0.00°
   关节 6:  180.00°

[测试 1.3] 查询末端执行器位置...
✓ 当前位置姿态：
   位置 (mm):  X= 200.00, Y=   0.00, Z= 150.00
   姿态 (deg): Rx= 180.00, Ry=   0.00, Rz=   0.00

[测试 1.4] 查询 I/O 状态...
✓ I/O 状态：
   输入 1: 0  输入 2: 0
   输出 1: 0  输出 2: 0
   急停状态: 释放

[测试 1.5] 查询完整机器人状态...
✓ 完整状态获取成功
   运动状态：已停止
   急停状态：释放

============================================================
连接测试完成！
============================================================
```

**✓ 如果所有测试通过**：连接正常，继续下一阶段

**✗ 如果测试失败**：
1. 确认服务器终端是否显示 "Listening for UDP commands on port 5001"
2. 检查防火墙设置
3. 尝试重启服务器

---

## 🤖 阶段 3：基础运动测试

> ⚠️ **安全提醒**：
> - 确保机器人周围无障碍物
> - 保持急停按钮可触及
> - 首次运动时站在机器人侧面观察
> - 准备好随时按下急停

### 步骤 3.1：测试单关节运动

**操作**：

创建测试脚本 `test_02_basic_motion.py`：

```python
#!/usr/bin/env python3
"""测试 2：基础运动测试"""

import sys
sys.path.insert(0, './Headless')

from robot_api import *
import time

print("=" * 60)
print("测试 2：基础运动测试")
print("=" * 60)
print("\n⚠️  安全提醒：")
print("   - 确保机器人周围无障碍物")
print("   - 保持急停按钮可触及")
print("   - 观察机器人运动，异常时立即按急停")
print("\n按 Enter 键开始测试...")
input()

# 测试 2.1：关节运动测试
print("\n[测试 2.1] 关节运动测试")
print("机器人将移动关节 1（底座旋转）")
print("运动范围：0° → 45° → -45° → 0°")
print("准备好后按 Enter...")
input()

try:
    # 记录初始位置
    initial_angles = get_robot_joint_angles()
    print(f"初始位置：{initial_angles}")

    # 移动到 45 度
    print("\n→ 移动到 45°...")
    move_robot_joints([45, -90, 180, 0, 0, 180], speed_percentage=30, wait_for_ack=True)
    time.sleep(0.5)

    current = get_robot_joint_angles()
    print(f"✓ 当前位置：关节 1 = {current[0]:.2f}°")

    # 移动到 -45 度
    print("\n→ 移动到 -45°...")
    move_robot_joints([-45, -90, 180, 0, 0, 180], speed_percentage=30, wait_for_ack=True)
    time.sleep(0.5)

    current = get_robot_joint_angles()
    print(f"✓ 当前位置：关节 1 = {current[0]:.2f}°")

    # 返回初始位置
    print("\n→ 返回初始位置...")
    move_robot_joints(initial_angles, speed_percentage=30, wait_for_ack=True)
    time.sleep(0.5)

    print("✓ 关节运动测试完成")

except Exception as e:
    print(f"✗ 测试失败：{e}")
    sys.exit(1)

time.sleep(2)

# 测试 2.2：多关节协调运动
print("\n" + "=" * 60)
print("[测试 2.2] 多关节协调运动测试")
print("机器人将执行一个简单的姿态变换")
print("准备好后按 Enter...")
input()

try:
    # 移动到测试姿态
    print("\n→ 移动到测试姿态...")
    test_pose = [30, -60, 150, 0, -30, 180]
    move_robot_joints(test_pose, duration=3.0, wait_for_ack=True)
    time.sleep(0.5)

    current = get_robot_joint_angles()
    print(f"✓ 到达测试姿态")
    print(f"  目标：{test_pose}")
    print(f"  实际：{[round(a, 1) for a in current]}")

    # 返回零位
    print("\n→ 返回零位...")
    home_robot(wait_for_ack=True)
    time.sleep(0.5)

    print("✓ 多关节协调运动测试完成")

except Exception as e:
    print(f"✗ 测试失败：{e}")
    sys.exit(1)

print("\n" + "=" * 60)
print("基础运动测试完成！")
print("=" * 60)
print("\n✓ 机器人可以正常执行关节运动")
print("✓ 可以继续测试笛卡尔运动")
```

运行测试：
```bash
python test_02_basic_motion.py
```

**预期行为**：
1. 机器人底座缓慢旋转到 45°
2. 旋转到 -45°
3. 返回 0°
4. 执行多关节协调运动
5. 返回零位

**观察要点**：
- ✓ 运动应该平滑，无抖动
- ✓ 关节应该同步启动和停止
- ✓ 没有异常噪音
- ✗ 如果有卡顿、抖动或异响 → 立即按急停

---

### 步骤 3.2：测试笛卡尔运动

创建测试脚本 `test_03_cartesian_motion.py`：

```python
#!/usr/bin/env python3
"""测试 3：笛卡尔运动测试"""

import sys
sys.path.insert(0, './Headless')

from robot_api import *
import time

print("=" * 60)
print("测试 3：笛卡尔空间运动测试")
print("=" * 60)
print("\n这个测试将验证机器人在笛卡尔空间的运动能力")
print("按 Enter 键开始...")
input()

# 确保机器人在已知状态
print("\n→ 机器人回零...")
home_robot(wait_for_ack=True)
time.sleep(1)

# 测试 3.1：基础笛卡尔运动
print("\n[测试 3.1] 笛卡尔位置运动")
print("机器人将移动到几个不同的笛卡尔位置")

try:
    # 获取当前位置
    start_pose = get_robot_pose()
    print(f"起始位置：X={start_pose[0]:.1f}, Y={start_pose[1]:.1f}, Z={start_pose[2]:.1f}")

    # 测试位置 1
    print("\n→ 移动到位置 1: [250, 0, 200]...")
    move_robot_pose([250, 0, 200, 180, 0, 0], speed_percentage=40, wait_for_ack=True)
    time.sleep(0.5)

    current = get_robot_pose()
    print(f"✓ 到达：X={current[0]:.1f}, Y={current[1]:.1f}, Z={current[2]:.1f}")

    # 测试位置 2
    print("\n→ 移动到位置 2: [250, 50, 200]...")
    move_robot_pose([250, 50, 200, 180, 0, 0], speed_percentage=40, wait_for_ack=True)
    time.sleep(0.5)

    current = get_robot_pose()
    print(f"✓ 到达：X={current[0]:.1f}, Y={current[1]:.1f}, Z={current[2]:.1f}")

    # 测试位置 3
    print("\n→ 移动到位置 3: [200, 50, 150]...")
    move_robot_pose([200, 50, 150, 180, 0, 0], speed_percentage=40, wait_for_ack=True)
    time.sleep(0.5)

    current = get_robot_pose()
    print(f"✓ 到达：X={current[0]:.1f}, Y={current[1]:.1f}, Z={current[2]:.1f}")

    print("\n✓ 笛卡尔位置运动测试完成")

except Exception as e:
    print(f"✗ 测试失败：{e}")
    print("可能原因：目标位置超出工作空间")

time.sleep(2)

# 测试 3.2：笛卡尔直线运动
print("\n" + "=" * 60)
print("[测试 3.2] 笛卡尔直线运动")
print("机器人将执行保证直线路径的运动")
print("准备好后按 Enter...")
input()

try:
    # 移动到起点
    print("\n→ 移动到起点...")
    move_robot_cartesian([200, -50, 180, 180, 0, 0], duration=3.0, wait_for_ack=True)
    time.sleep(0.5)
    print("✓ 到达起点")

    # 执行直线运动
    print("\n→ 执行直线运动到终点...")
    move_robot_cartesian([200, 50, 180, 180, 0, 0], duration=4.0, wait_for_ack=True)
    time.sleep(0.5)
    print("✓ 到达终点")

    # 返回
    print("\n→ 直线返回起点...")
    move_robot_cartesian([200, -50, 180, 180, 0, 0], duration=4.0, wait_for_ack=True)
    time.sleep(0.5)
    print("✓ 返回起点")

    print("\n✓ 笛卡尔直线运动测试完成")

except Exception as e:
    print(f"✗ 测试失败：{e}")

time.sleep(2)

# 测试 3.3：点动测试
print("\n" + "=" * 60)
print("[测试 3.3] 笛卡尔点动测试")
print("机器人将在笛卡尔空间进行小幅度点动")
print("准备好后按 Enter...")
input()

try:
    print("\n→ Z 轴正向点动 (向上 20mm)...")
    jog_cartesian(frame='WRF', axis='Z+', speed_percentage=30, duration=1.0, wait_for_ack=True)
    time.sleep(0.5)
    print("✓ 完成")

    print("\n→ X 轴正向点动 (向前 20mm)...")
    jog_cartesian(frame='WRF', axis='X+', speed_percentage=30, duration=1.0, wait_for_ack=True)
    time.sleep(0.5)
    print("✓ 完成")

    print("\n→ X 轴负向点动 (向后 20mm)...")
    jog_cartesian(frame='WRF', axis='X-', speed_percentage=30, duration=1.0, wait_for_ack=True)
    time.sleep(0.5)
    print("✓ 完成")

    print("\n→ Z 轴负向点动 (向下 20mm)...")
    jog_cartesian(frame='WRF', axis='Z-', speed_percentage=30, duration=1.0, wait_for_ack=True)
    time.sleep(0.5)
    print("✓ 完成")

    print("\n✓ 点动测试完成")

except Exception as e:
    print(f"✗ 测试失败：{e}")

# 返回零位
print("\n→ 返回零位...")
home_robot(wait_for_ack=True)

print("\n" + "=" * 60)
print("笛卡尔运动测试完成！")
print("=" * 60)
print("\n✓ 机器人可以在笛卡尔空间正常运动")
print("✓ 直线路径功能正常")
print("✓ 点动功能正常")
```

运行测试：
```bash
python test_03_cartesian_motion.py
```

**预期行为**：
- 机器人末端沿直线移动到不同位置
- 点动时沿指定轴移动
- 所有运动平滑无抖动

---

## 🦾 阶段 4：夹爪控制测试

### 步骤 4.1：测试电动夹爪

创建测试脚本 `test_04_gripper.py`：

```python
#!/usr/bin/env python3
"""测试 4：夹爪控制测试"""

import sys
sys.path.insert(0, './Headless')

from robot_api import *
import time

print("=" * 60)
print("测试 4：夹爪控制测试")
print("=" * 60)

# 检查夹爪类型
print("\n请确认你的夹爪类型：")
print("1 - 电动夹爪 (Electric Gripper)")
print("2 - 气动夹爪 (Pneumatic Gripper)")
gripper_type = input("请输入选项 (1/2): ").strip()

if gripper_type == "1":
    print("\n测试电动夹爪...")
    print("按 Enter 开始测试...")
    input()

    try:
        # 测试 4.1：校准夹爪
        print("\n[测试 4.1] 校准夹爪...")
        print("→ 开始校准（夹爪会完全打开）...")
        control_electric_gripper(action='calibrate', wait_for_ack=True)
        time.sleep(2)

        # 查询状态
        status = get_electric_gripper_status(verbose=False)
        if status:
            print(f"✓ 校准完成")
            print(f"  当前位置: {status[1]}")
            print(f"  状态字节: {status[4]}")

        time.sleep(1)

        # 测试 4.2：完全打开
        print("\n[测试 4.2] 完全打开夹爪...")
        control_electric_gripper(action='move', position=0, speed=100, wait_for_ack=True)
        time.sleep(2)

        status = get_electric_gripper_status(verbose=False)
        if status:
            print(f"✓ 夹爪已打开")
            print(f"  当前位置: {status[1]}")

        time.sleep(1)

        # 测试 4.3：完全关闭
        print("\n[测试 4.3] 完全关闭夹爪...")
        control_electric_gripper(action='move', position=255, speed=100, current=500, wait_for_ack=True)
        time.sleep(2)

        status = get_electric_gripper_status(verbose=False)
        if status:
            print(f"✓ 夹爪已关闭")
            print(f"  当前位置: {status[1]}")
            print(f"  物体检测: {status[5]}")

        time.sleep(1)

        # 测试 4.4：中间位置
        print("\n[测试 4.4] 移动到中间位置...")
        control_electric_gripper(action='move', position=128, speed=150, wait_for_ack=True)
        time.sleep(2)

        status = get_electric_gripper_status(verbose=False)
        if status:
            print(f"✓ 夹爪在中间位置")
            print(f"  当前位置: {status[1]}")

        time.sleep(1)

        # 测试 4.5：打开准备下次测试
        print("\n[测试 4.5] 打开夹爪...")
        control_electric_gripper(action='move', position=0, speed=100, wait_for_ack=True)
        time.sleep(2)
        print("✓ 夹爪已打开")

        # 完整状态显示
        print("\n[最终状态]")
        get_electric_gripper_status(verbose=True)

        print("\n✓ 电动夹爪测试完成")
        print("\n测试项目：")
        print("  ✓ 夹爪校准")
        print("  ✓ 完全打开")
        print("  ✓ 完全关闭")
        print("  ✓ 中间位置控制")
        print("  ✓ 状态查询")

    except Exception as e:
        print(f"✗ 测试失败：{e}")

elif gripper_type == "2":
    print("\n测试气动夹爪...")
    print("请选择使用的数字输出端口 (通常是 1 或 2): ")
    port = int(input("端口号: ").strip())

    print("\n按 Enter 开始测试...")
    input()

    try:
        # 测试 4.1：打开夹爪
        print("\n[测试 4.1] 打开气动夹爪...")
        control_pneumatic_gripper(action='open', port=port, wait_for_ack=True)
        time.sleep(1)

        # 查询 IO 状态
        io_status = get_robot_io(verbose=False)
        if io_status:
            output_state = io_status[port + 1]  # OUT1 is index 2, OUT2 is index 3
            print(f"✓ 夹爪打开命令已发送")
            print(f"  输出端口 {port} 状态: {output_state}")

        time.sleep(2)

        # 测试 4.2：关闭夹爪
        print("\n[测试 4.2] 关闭气动夹爪...")
        control_pneumatic_gripper(action='close', port=port, wait_for_ack=True)
        time.sleep(1)

        io_status = get_robot_io(verbose=False)
        if io_status:
            output_state = io_status[port + 1]
            print(f"✓ 夹爪关闭命令已发送")
            print(f"  输出端口 {port} 状态: {output_state}")

        time.sleep(2)

        # 测试 4.3：再次打开
        print("\n[测试 4.3] 再次打开夹爪...")
        control_pneumatic_gripper(action='open', port=port, wait_for_ack=True)
        time.sleep(1)
        print("✓ 夹爪已打开")

        print("\n✓ 气动夹爪测试完成")
        print("\n测试项目：")
        print("  ✓ 打开夹爪")
        print("  ✓ 关闭夹爪")
        print("  ✓ IO 端口控制")

    except Exception as e:
        print(f"✗ 测试失败：{e}")

else:
    print("✗ 无效选项")

print("\n" + "=" * 60)
print("夹爪控制测试完成！")
print("=" * 60)
```

运行测试：
```bash
python test_04_gripper.py
```

**预期行为**：
- 电动夹爪：平滑开合，可以听到电机声音
- 气动夹爪：快速开合，可以听到气流声音

---

## 🎨 阶段 5：高级运动测试

### 步骤 5.1：测试平滑圆形轨迹

创建测试脚本 `test_05_smooth_motion.py`：

```python
#!/usr/bin/env python3
"""测试 5：高级平滑运动测试"""

import sys
sys.path.insert(0, './Headless')

from robot_api import *
import time

print("=" * 60)
print("测试 5：高级平滑运动测试")
print("=" * 60)
print("\n这个测试将展示机器人的高级运动能力")
print("包括圆形、螺旋、样条曲线等复杂轨迹")
print("\n按 Enter 键开始...")
input()

# 准备
print("\n→ 机器人移动到测试起点...")
move_robot_joints([0, -90, 180, 0, -45, 180], duration=3.0, wait_for_ack=True)
time.sleep(1)

# 测试 5.1：圆形轨迹
print("\n" + "=" * 60)
print("[测试 5.1] 圆形轨迹测试")
print("机器人末端将画一个水平圆形")
print("圆心: [220, 0, 180], 半径: 40mm")
print("准备好后按 Enter...")
input()

try:
    print("\n→ 执行圆形轨迹...")
    smooth_circle(
        center=[220, 0, 180],
        radius=40,
        plane='XY',
        duration=8.0,
        clockwise=False,
        wait_for_ack=True
    )
    time.sleep(1)
    print("✓ 圆形轨迹完成")

except Exception as e:
    print(f"✗ 测试失败：{e}")

time.sleep(2)

# 测试 5.2：圆弧运动
print("\n" + "=" * 60)
print("[测试 5.2] 圆弧运动测试")
print("机器人将执行一个 90° 的圆弧运动")
print("准备好后按 Enter...")
input()

try:
    # 移动到起点
    start_pos = [200, -40, 180, 180, 0, 0]
    print("\n→ 移动到圆弧起点...")
    move_robot_cartesian(start_pos, duration=2.0, wait_for_ack=True)
    time.sleep(1)

    # 执行圆弧
    print("\n→ 执行圆弧运动...")
    smooth_arc_parametric(
        end_pose=[240, 0, 180, 180, 0, 0],
        radius=40,
        arc_angle=90,
        duration=4.0,
        wait_for_ack=True
    )
    time.sleep(1)
    print("✓ 圆弧运动完成")

except Exception as e:
    print(f"✗ 测试失败：{e}")

time.sleep(2)

# 测试 5.3：样条曲线
print("\n" + "=" * 60)
print("[测试 5.3] 样条曲线测试")
print("机器人将通过多个路点执行平滑曲线")
print("准备好后按 Enter...")
input()

try:
    waypoints = [
        [200, 0, 150, 180, 0, 0],
        [220, 30, 170, 180, 0, 0],
        [240, 0, 190, 180, 0, 0],
        [220, -30, 170, 180, 0, 0],
        [200, 0, 150, 180, 0, 0]
    ]

    print("\n→ 执行样条曲线...")
    print(f"  路点数量: {len(waypoints)}")
    smooth_spline(waypoints, duration=10.0, wait_for_ack=True)
    time.sleep(1)
    print("✓ 样条曲线完成")

except Exception as e:
    print(f"✗ 测试失败：{e}")

time.sleep(2)

# 测试 5.4：螺旋运动（可选，较复杂）
print("\n" + "=" * 60)
print("[测试 5.4] 螺旋运动测试（可选）")
print("这个测试会执行螺旋上升运动，耗时较长")
response = input("是否执行？(y/n): ").strip().lower()

if response == 'y':
    try:
        print("\n→ 执行螺旋运动...")
        smooth_helix(
            center=[220, 0, 120],
            radius=25,
            pitch=15,  # 每圈上升 15mm
            height=60,  # 总高度 60mm（4圈）
            duration=15.0,
            wait_for_ack=True
        )
        time.sleep(1)
        print("✓ 螺旋运动完成")

    except Exception as e:
        print(f"✗ 测试失败：{e}")
else:
    print("跳过螺旋运动测试")

# 返回零位
print("\n→ 返回零位...")
home_robot(wait_for_ack=True)

print("\n" + "=" * 60)
print("高级平滑运动测试完成！")
print("=" * 60)
print("\n✓ 圆形轨迹")
print("✓ 圆弧运动")
print("✓ 样条曲线")
if response == 'y':
    print("✓ 螺旋运动")
print("\n机器人已具备执行复杂轨迹的能力！")
```

运行测试：
```bash
python test_05_smooth_motion.py
```

**预期行为**：
- 圆形轨迹：末端画出完整的圆
- 圆弧：平滑的 90° 弧线
- 样条：通过所有路点的平滑曲线
- 螺旋：螺旋式上升运动

**观察要点**：
- 运动应该非常平滑，无突变
- 速度恒定
- 没有停顿或加速度突变

---

## 📹 阶段 6：视觉系统测试

### 步骤 6.1：测试相机连接

创建测试脚本 `test_06_vision.py`：

```python
#!/usr/bin/env python3
"""测试 6：视觉系统测试"""

import sys
sys.path.insert(0, './Headless')

print("=" * 60)
print("测试 6：视觉系统测试")
print("=" * 60)

# 检查相机是否连接
print("\n[检查 1] 检测 RealSense 相机...")
try:
    import pyrealsense2 as rs
    ctx = rs.context()
    devices = ctx.query_devices()

    if len(devices) == 0:
        print("✗ 未检测到 RealSense 相机")
        print("\n请检查：")
        print("  1. 相机是否通过 USB 3.0 连接")
        print("  2. 相机是否有电（LED 灯是否亮起）")
        print("  3. realsense-viewer 是否能检测到相机")
        sys.exit(1)
    else:
        print(f"✓ 检测到 {len(devices)} 个 RealSense 设备")
        for i, dev in enumerate(devices):
            print(f"  设备 {i+1}:")
            print(f"    名称: {dev.get_info(rs.camera_info.name)}")
            print(f"    序列号: {dev.get_info(rs.camera_info.serial_number)}")

except ImportError:
    print("✗ pyrealsense2 模块未安装")
    print("  安装命令: pip3 install pyrealsense2")
    sys.exit(1)
except Exception as e:
    print(f"✗ 相机检测失败：{e}")
    sys.exit(1)

# 测试视觉控制器
print("\n[检查 2] 初始化视觉控制器...")
try:
    from Headless.Vision import vision_controller

    print("→ 启动相机...")
    vision = vision_controller.VisionController()
    vision.start()

    import time
    time.sleep(2)  # 等待相机稳定

    print("✓ 视觉控制器初始化成功")

    # 测试获取图像
    print("\n[检查 3] 获取相机图像...")
    color_frame, depth_frame = vision.get_frames()

    if color_frame is not None and depth_frame is not None:
        import numpy as np
        print("✓ 成功获取图像")
        print(f"  彩色图像尺寸: {color_frame.shape}")
        print(f"  深度图像尺寸: {depth_frame.shape}")

        # 显示图像
        import cv2
        print("\n→ 显示相机画面（按 'q' 键退出）...")
        print("  请检查图像质量和清晰度")

        for i in range(100):  # 显示约 3 秒
            color_frame, depth_frame = vision.get_frames()
            if color_frame is not None:
                # 创建深度彩色图
                depth_colormap = cv2.applyColorMap(
                    cv2.convertScaleAbs(depth_frame, alpha=0.03),
                    cv2.COLORMAP_JET
                )

                # 并排显示
                combined = np.hstack((color_frame, depth_colormap))
                cv2.imshow('相机测试 - 彩色 | 深度', combined)

                if cv2.waitKey(30) & 0xFF == ord('q'):
                    break

        cv2.destroyAllWindows()
        print("✓ 图像显示测试完成")
    else:
        print("✗ 无法获取图像")
        vision.stop()
        sys.exit(1)

    # 检查标定文件
    print("\n[检查 4] 检查手眼标定文件...")
    import os
    calib_file = vision.calibration_file
    if os.path.exists(calib_file):
        print(f"✓ 找到标定文件: {calib_file}")

        # 加载标定数据
        import numpy as np
        calib_data = np.load(calib_file)
        print("  标定文件包含:")
        for key in calib_data.files:
            print(f"    - {key}")
    else:
        print(f"⚠ 未找到标定文件: {calib_file}")
        print("  视觉引导功能需要先进行手眼标定")
        print("  运行: python Headless/Vision/calibrate_hand_eye.py")

    # 测试 3D 定位（如果有标定）
    if os.path.exists(calib_file):
        print("\n[检查 5] 测试 3D 定位功能...")
        print("请在相机前放置一个物体")
        input("准备好后按 Enter...")

        # 获取当前帧
        color_frame, depth_frame = vision.get_frames()

        # 测试转换一个点（图像中心）
        test_x, test_y = 320, 240
        print(f"\n→ 测试转换图像坐标 ({test_x}, {test_y}) 到 3D...")

        # 获取深度
        depth_value = depth_frame[test_y, test_x]
        print(f"  深度值: {depth_value} mm")

        if depth_value > 0:
            print("✓ 深度数据有效")
        else:
            print("⚠ 深度数据无效（可能距离太近或表面反光）")

    # 关闭相机
    print("\n→ 关闭相机...")
    vision.stop()
    print("✓ 相机已关闭")

    print("\n" + "=" * 60)
    print("视觉系统测试完成！")
    print("=" * 60)
    print("\n✓ 相机连接正常")
    print("✓ 图像获取正常")
    if os.path.exists(calib_file):
        print("✓ 手眼标定文件存在")
        print("\n可以进行视觉引导操作测试")
    else:
        print("⚠ 需要进行手眼标定才能使用视觉引导功能")

except ImportError as e:
    print(f"✗ 模块导入失败：{e}")
    print("\n请确保已安装：")
    print("  pip3 install opencv-python pyrealsense2")
except Exception as e:
    print(f"✗ 测试失败：{e}")
    import traceback
    traceback.print_exc()
```

运行测试：
```bash
python test_06_vision.py
```

**预期结果**：
- 检测到 RealSense D435I 相机
- 显示彩色和深度图像
- 图像清晰，深度数据有效

**如果相机未检测到**：
1. 使用 USB 3.0 端口（蓝色）
2. 运行 `realsense-viewer` 测试相机
3. 更新 RealSense SDK

---

### 步骤 6.2：手眼标定（如果需要）

如果测试显示缺少标定文件，需要进行手眼标定：

**操作**：

1. 打印 ChArUco 标定板：
```bash
cd Headless/Vision
python generate_charuco_board.py
```
打印生成的 PDF 文件（A4 纸）

2. 将标定板平放在机器人前方的桌面上

3. 运行标定程序：
```bash
python calibrate_hand_eye.py
```

4. 按照提示操作：
   - 机器人会自动移动到多个位置
   - 相机会采集标定板图像
   - 自动计算手眼变换矩阵
   - 保存标定结果

5. 验证标定：
```bash
python validate_calibration.py
```

**预期精度**：±3mm 以内

---

## 🤖 阶段 7：Gemini AI 控制测试

### 步骤 7.1：测试文本模式控制

**前提**：
- 已配置 `.env` 文件中的 `GEMINI_API_KEY`
- 机器人控制服务器正在运行

**操作**：

打开新终端，启动 Gemini 控制器：

```bash
cd Headless/Gemini
python gemini.py --mode text
```

**预期输出**：
```
Initializing Gemini controller in TEXT mode...
✓ Vision system initialized
✓ Camera started
✓ Gemini client connected
✓ Session started

Mode: TEXT (Step-by-step control)
Input: Text
Response: Text

Ready! Type your commands...
Commands:
  - Type robot commands in natural language
  - 'quit' or 'exit' to stop

你:
```

**测试命令**：

1. **测试 1：查询状态**
```
你: 机器人现在在什么位置？

预期响应：
AI: 让我查询一下当前位置...
    机器人当前位置：X=200.0mm, Y=0.0mm, Z=150.0mm
    姿态：Rx=180°, Ry=0°, Rz=0°
```

2. **测试 2：简单移动**
```
你: 请向上移动 50mm

预期响应：
AI: 好的，我将末端执行器向上移动50mm...
    [机器人向上移动]
    完成！已向上移动50mm
```

3. **测试 3：关节运动**
```
你: 把第一个关节旋转到 45 度

预期响应：
AI: 我将第一个关节旋转到45度...
    [机器人底座旋转]
    完成！关节1现在在45度
```

4. **测试 4：夹爪控制**
```
你: 打开夹爪

预期响应：
AI: 打开夹爪...
    [夹爪打开]
    夹爪已打开
```

5. **测试 5：视觉检测**
```
你: 告诉我你看到了什么

预期响应：
AI: 让我查看相机画面...
    我看到了 [物体描述]
    在图像的 [位置] 有一个 [颜色/形状] 的物体
```

**观察要点**：
- AI 能理解自然语言命令
- 机器人正确执行动作
- AI 提供清晰的反馈

---

### 步骤 7.2：测试自主模式（高级）

**操作**：

停止文本模式（输入 `quit`），启动自主模式：

```bash
python gemini.py --mode autonomous
```

**预期输出**：
```
Initializing Gemini controller in AUTONOMOUS mode...
✓ Vision system initialized
✓ Gemini client connected with function calling

Mode: AUTONOMOUS (Compositional multi-step)
Input: Text
Response: Text

Ready for complex tasks!
你:
```

**测试任务**：

1. **测试 1：简单抓取任务**
```
你: 找到红色的物体并抓取它

预期行为：
1. AI 分析任务
2. 相机扫描环境
3. 识别红色物体
4. 计算抓取位置
5. 规划运动路径
6. 执行抓取
7. 报告结果
```

2. **测试 2：放置任务**
```
你: 把它放到左边

预期行为：
1. AI 理解"左边"
2. 规划放置位置
3. 移动到目标
4. 放置物体
5. 松开夹爪
6. 返回
```

3. **测试 3：复杂任务**
```
你: 把所有红色方块移到蓝色盒子里

预期行为：
1. 扫描环境
2. 识别所有红色方块
3. 识别蓝色盒子
4. 逐个抓取并放置
5. 报告完成情况
```

**观察要点**：
- AI 能分解复杂任务
- 自动调用多个函数
- 错误时能重试或调整策略

---

### 步骤 7.3：测试语音模式（可选）

**操作**：

启动语音输入模式：

```bash
python gemini.py --mode text --input audio
```

**使用方法**：
1. 按住**空格键**开始录音
2. 说出命令（例如："向上移动五十毫米"）
3. 松开空格键
4. AI 处理并执行

**测试命令**：
- "机器人回零"
- "打开夹爪"
- "向前移动一百毫米"
- "抓取红色的物体"

---

## 📊 完整功能验证清单

完成所有测试后，使用这个清单验证：

```
✓ 核心功能
  ✓ 串口连接正常
  ✓ UDP 通信正常
  ✓ 状态查询功能
  ✓ 急停功能

✓ 基础运动
  ✓ 单关节运动
  ✓ 多关节协调运动
  ✓ 回零功能
  ✓ 速度控制

✓ 笛卡尔运动
  ✓ 位置运动（move_robot_pose）
  ✓ 直线运动（move_robot_cartesian）
  ✓ 点动控制（jog_cartesian）
  ✓ 位置精度

✓ 夹爪控制
  ✓ 开合动作
  ✓ 位置控制
  ✓ 状态反馈
  ✓ 力控制（电动夹爪）

✓ 高级运动
  ✓ 圆形轨迹
  ✓ 圆弧运动
  ✓ 样条曲线
  ✓ 螺旋运动
  ✓ 混合运动

✓ 视觉系统
  ✓ 相机连接
  ✓ 图像获取
  ✓ 深度数据
  ✓ 手眼标定
  ✓ 3D 定位

✓ AI 控制
  ✓ 文本模式
  ✓ 自主模式
  ✓ 语音输入（可选）
  ✓ 视觉理解
  ✓ 任务规划

✓ 综合应用
  ✓ 视觉引导抓取
  ✓ 自然语言控制
  ✓ 多步骤任务
  ✓ 错误恢复
```

---

## 🎯 下一步建议

完成所有测试后，你可以：

### 1. 开发自定义应用
创建自己的控制脚本，实现特定任务

### 2. 优化性能
- 调整运动速度参数
- 优化轨迹规划
- 改进视觉识别

### 3. 扩展功能
- 添加新的工具函数
- 集成其他传感器
- 开发自定义 Gemini 工具

### 4. 参与社区
- 分享你的应用案例
- 报告问题和建议
- 贡献代码改进

---

## 📞 遇到问题？

### 常见问题速查

| 问题 | 检查项 | 解决方案 |
|------|--------|---------|
| 串口连接失败 | USB 连接、端口号 | 检查 com_port.txt |
| 机器人不动 | 急停状态 | 释放急停，按 'e' |
| UDP 无响应 | 服务器运行、防火墙 | 重启服务器 |
| 运动异常 | 障碍物、关节限位 | 清理工作空间 |
| 相机无法启动 | USB 3.0、驱动 | 运行 realsense-viewer |
| Gemini 错误 | API 密钥、网络 | 检查 .env 文件 |
| IK 求解失败 | 目标位置 | 调整到可达范围 |

### 获取帮助

1. **查看文档**：
   - `README.md` - 项目概述
   - `API-Specific-README.md` - API 详细文档
   - `中文使用说明.md` - 中文使用指南

2. **检查日志**：
   - 服务器终端输出
   - 错误堆栈信息
   - 机器人状态查询

3. **社区支持**：
   - GitHub Issues
   - PAROL6 Discord 频道
   - 项目讨论区

---

## ✅ 测试完成！

恭喜！如果你完成了所有测试，你的 PAROL6 机械臂系统已经完全配置好并可以使用了。

**你现在可以：**
- ✓ 使用 Python API 编程控制机器人
- ✓ 通过自然语言命令控制机器人
- ✓ 使用视觉引导进行智能抓取
- ✓ 执行复杂的多步骤任务
- ✓ 开发自己的机器人应用

**祝你使用愉快！🤖🎉**
